# # Ethical AI Software
Collection of links for Ethical AI, Fairness & Transperency libraries.

Note this is mostly Python centric but welcome additions regardless of the language.


**Deon**
- **Summary**: An ethics checklist for data scientists
- **Repo**: https://github.com/drivendataorg/deon
- **Docs**: https://deon.drivendata.org/

**Alibi**
- **Summary**: Alibi is an open source Python library aimed at machine learning model inspection and interpretation
- **Repo**: https://github.com/SeldonIO/alibi
- **Docs**: https://**Docs**.seldon.io/projects/alibi/en/stable


**AI Fairness 360**
- **Summary**: The AI Fairness 360 toolkit is an extensible open-source library containg techniques developed by the research community to help detect and mitigate bias in machine learning models throughout the AI application lifecycle.
- **Repo**: https://github.com/Trusted-AI/AIF360
- **Docs**: https://aif360.mybluemix.net/


**Interpret**
- **Summary**: InterpretML is an open-source package that incorporates state-of-the-art machine learning interpretability techniques under one roof.
- **Repo**: https://github.com/interpretml/interpret
- **Docs**: N/A


**Fairlean**
- **Summary**: Fairlearn is a Python package that empowers developers of artificial intelligence (AI) systems to assess their system's fairness and mitigate any observed unfairness issues
- **Repo**: https://github.com/fairlearn/fairlearn
- **Docs**: https://fairlearn.github.io/master/index.html


**Fairness Indicators**
- **Summary**: Fairness Indicators is designed to support teams in evaluating, improving, and comparing models for fairness concerns in partnership with the broader Tensorflow toolkit.
- **Repo**: https://github.com/tensorflow/fairness-indicators
- **Docs**: https://www.tensorflow.org/tfx/guide/fairness_indicators


**FAT Forensics**
- **Summary**: FAT Forensics is a Python toolkit for evaluating Fairness, Accountability and Transparency of Artificial Intelligence systems
- **Repo**: https://github.com/fat-forensics/fat-forensics
- **Docs**: https://fat-forensics.org/


**Anchor**
- **Summary**: An anchor explanation is a rule that sufficiently “anchors” the prediction locally – such that changes to the rest of the feature values of the instance do not matter. In other words, for instances on which the anchor holds, the prediction is (almost) always the same
- **Repo**: https://github.com/marcotcr/anchor
- **Paper**: https://homes.cs.washington.edu/~marcotcr/aaai18.pdf


**PyCEbox**
- **Summary**: A Python implementation of individual conditional expecation plots inspired by R's [ICEbox](https://cran.r-project.org/web/packages/ICEbox/index.html)
- **Repo**: https://github.com/AustinRochford/PyCEbox
- **Docs**: http://austinrochford.github.io/PyCEbox/docs/


**What-If Tool**
- **Summary**: The What-If Tool (WIT) provides an easy-to-use interface for expanding understanding of a black-box classification or regression ML model
- **Repo**: https://github.com/pair-code/what-if-tool
- **Docs**: https://pair-code.github.io/what-if-tool/


**LIME**
- **Summary**: This project is about explaining what machine learning classifiers (or models) are doing
- **Repo**: https://github.com/marcotcr/lime
- **Paper**: https://arxiv.org/abs/1602.04938


**SHAP**
- **Summary**: SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model
- **Repo**: https://github.com/slundberg/shap


**Yellowbrick**
- **Summary**: Yellowbrick extends the Scikit-Learn API to make model selection and hyperparameter tuning easier. Under the hood, it’s using Matplotlib.
- **Repo**: https://github.com/DistrictDataLabs/yellowbrick
- **Docs**: https://www.scikit-yb.org/en/latest/


**Tensorflow Fairness Indicators**
- **Summary**: Fairness Indicators is designed to support teams in evaluating, improving, and comparing models for fairness concerns in partnership with the broader Tensorflow toolkit.
- **Repo**: https://github.com/tensorflow/fairness-indicators
- **Docs**: https://www.tensorflow.org/responsible_ai


**PyCM**
- **Summary**: PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters.
- **Repo**: https://github.com/sepandhaghighi/pycm
- **Docs**: https://www.pycm.ir/
